{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Performs Research with Multi-Agent Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install pyautogen~=0.2.0b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/vscode/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in /home/vscode/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/vscode/.local/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/vscode/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\", \"gpt-4-1106-preview\"],\n",
    "    },\n",
    ")\n",
    "config_list_gpt35 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "         \"model\": [\"gpt-3.5-turbo-16k-0613\"],\n",
    "        # \"model\": [\"gpt-3.5-turbo\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "gpt_config = {\n",
    "    \"cache_seed\": 42,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,  # Controls randomness of responses\n",
    "    \"config_list\": config_list_gpt35,  # Presumably a list of additional GPT-3.5 configurations\n",
    "    \"timeout\": 120,  # Maximum time for the agent to respond\n",
    "}\n",
    "\n",
    "# Load agent configurations from the JSON file\n",
    "with open('agents_config.json', 'r') as file:\n",
    "    agents_config = json.load(file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user proxy\n"
     ]
    }
   ],
   "source": [
    "# Initialize agents using the configurations from the JSON file\n",
    "Agents_1 = []\n",
    "Agents_2 = []\n",
    "Agents_3 = []\n",
    "\n",
    "for key, config in agents_config.items():\n",
    "    # Extracting relevant details from the new JSON structure\n",
    "    role = config['Role']\n",
    "    demographic = config['Demographic']\n",
    "    opinions = config['Opinions']\n",
    "    task = config['Task']\n",
    "    format_requirement = config['Format']\n",
    "\n",
    "    # Constructing a system message based on the new JSON structure\n",
    "    system_message_1 = f\"[Role] {role}\\n[Opinions] {opinions}\\n[Task] {task}\\n[Format] {format_requirement}\"\n",
    "    system_message_2 = f\"[Role] {role}\\n[Opinions] {opinions}\\n[Format] {format_requirement}\"\n",
    "    system_message_3 = f\"[Role] {role}\\n[Demographic] {demographic}\\n[Opinions] {opinions}\\n[Task] {task}\\n[Format] {format_requirement}\"\n",
    "\n",
    "    # Creating the agent with the new system message\n",
    "    agent_1 = autogen.AssistantAgent(\n",
    "        name=key,  # 'key' is the name of the agent\n",
    "        llm_config=gpt_config,\n",
    "        system_message=system_message_1\n",
    "    )\n",
    "    agent_2 = autogen.AssistantAgent(\n",
    "    name=key,  # 'key' is the name of the agent\n",
    "    llm_config=gpt_config,\n",
    "    system_message=system_message_1\n",
    ")\n",
    "    agent_3 = autogen.AssistantAgent(\n",
    "    name=key,  # 'key' is the name of the agent\n",
    "    llm_config=gpt_config,\n",
    "    system_message=system_message_1\n",
    ")\n",
    "    Agents_1.append(agent_1)\n",
    "    Agents_2.append(agent_2)\n",
    "    Agents_3.append(agent_3)\n",
    "\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"Government\",\n",
    "   system_message=\"A human admin. Interact with all other agents to discuss the plan. Plan execution needs to be approved by this admin.\",\n",
    "   code_execution_config=False,\n",
    ")\n",
    "\n",
    "Agents_1.append(user_proxy)\n",
    "Agents_2.append(user_proxy)\n",
    "Agents_3.append(user_proxy)\n",
    "print(\"Added user proxy\")\n",
    "\n",
    "# Create a group chat with all agents\n",
    "groupchat_1 = autogen.GroupChat(\n",
    "    agents = Agents_1,\n",
    "    messages=[],\n",
    "    max_round=100\n",
    ")\n",
    "groupchat_2 = autogen.GroupChat(\n",
    "    agents = Agents_2,\n",
    "    messages=[],\n",
    "    max_round=100\n",
    ")\n",
    "groupchat_3 = autogen.GroupChat(\n",
    "    agents = Agents_3,\n",
    "    messages=[],\n",
    "    max_round=100\n",
    ")\n",
    "\n",
    "manager_1 = autogen.GroupChatManager(groupchat=groupchat_1, llm_config=gpt_config)\n",
    "manager_2 = autogen.GroupChatManager(groupchat=groupchat_1, llm_config=gpt_config)\n",
    "manager_3 = autogen.GroupChatManager(groupchat=groupchat_1, llm_config=gpt_config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGovernment\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "[Role] I am the government for the Kendall Square renovation project.\n",
      "[Background] An old government building in the center of Kendall Square will be torn down for renovation. \n",
      "[Opinions] My proposed plan involves transforming an unused government building into affordable residential units, specifically designed to cater to low-income individuals and families, thereby addressing the issue of lack of low-income housing in the area. However, a potential drawback is the challenge of ensuring that the renovation meets all the necessary residential standards, including safety, accessibility, and comfort, which might require significant renovation costs.  There might also be resistance from existing neighborhood residents who may have concerns about the change in community dynamics and the impact on local services and infrastructure. Provide your personal opinion on this proposal.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to chat_manager):\n",
      "\n",
      "I partially agree with the government's proposal for the Kendall Square renovation project. Here's why:\n",
      "\n",
      "- Affordable housing is crucial, and repurposing the government building for low-income residential units is a step in the right direction.\n",
      "- However, it is important to ensure that the renovation meets all necessary residential standards, including safety, accessibility, and comfort, without compromising on quality.\n",
      "- To address concerns from existing residents, the government should engage in community outreach and provide adequate support for local services and infrastructure.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['affordable', 'safety', 'quality', 'community']\n",
      "Extent =  ['partially']\n",
      "Opinion =  ['agree']\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.647, 'pos': 0.353, 'compound': 0.9538}\n",
      "\u001b[33mLow_Income_Advocacy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\u001b[33mMIT_Management\u001b[0m (to chat_manager):\n",
      "\n",
      "I strongly agree with the government's proposal for the Kendall Square renovation project. Here's why:\n",
      "\n",
      "- The lack of affordable housing is a pressing issue, and repurposing the government building into low-income residential units will help address this problem.\n",
      "- It is crucial to ensure that the renovation meets all necessary residential standards, including safety, accessibility, and comfort, to provide a high-quality living environment for low-income individuals and families.\n",
      "- The government should actively engage with the community to address concerns and provide support for local services and infrastructure to ensure a smooth transition and positive impact on the neighborhood.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['affordable', 'safety', 'community']\n",
      "Extent =  ['strongly']\n",
      "Opinion =  ['agree']\n",
      "Sentiment Score =  {'neg': 0.067, 'neu': 0.548, 'pos': 0.385, 'compound': 0.9674}\n",
      "\u001b[33mLocal_Business\u001b[0m (to chat_manager):\n",
      "\n",
      "I partially agree with the government's proposal for the Kendall Square renovation project. Here's why:\n",
      "\n",
      "- Repurposing the government building into affordable residential units is a positive step towards addressing the lack of low-income housing in the area.\n",
      "- However, it is important to carefully consider the renovation costs and ensure that the necessary residential standards, including safety, accessibility, and comfort, are met without compromising on quality.\n",
      "- The government should also actively engage with the existing neighborhood residents to address their concerns and provide support for local services and infrastructure.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['affordable', 'costs', 'safety', 'quality']\n",
      "Extent =  ['partially']\n",
      "Opinion =  ['agree']\n",
      "Sentiment Score =  {'neg': 0.033, 'neu': 0.609, 'pos': 0.358, 'compound': 0.9607}\n",
      "\u001b[33mMIT_Student\u001b[0m (to chat_manager):\n",
      "\n",
      "MIT Student:\n",
      "\n",
      "I partially agree with the government's proposal for the Kendall Square renovation project. Here's why:\n",
      "\n",
      "- Repurposing the government building into affordable residential units is a positive step towards addressing the lack of low-income housing in the area.\n",
      "- However, it is important to ensure that the renovation meets all necessary residential standards, including safety, accessibility, and comfort, without compromising on quality.\n",
      "- The government should also consider the potential impact on the community dynamics and provide support for local services and infrastructure to address any concerns from existing residents.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['affordable', 'safety', 'quality', 'community']\n",
      "Extent =  ['partially']\n",
      "Opinion =  ['agree']\n",
      "Sentiment Score =  {'neg': 0.034, 'neu': 0.663, 'pos': 0.303, 'compound': 0.946}\n",
      "\u001b[33mEmployee\u001b[0m (to chat_manager):\n",
      "\n",
      "MIT Open Space Programming Office Employee:\n",
      "\n",
      "I partially agree with the government's proposal for the Kendall Square renovation project. Here's why:\n",
      "\n",
      "- Repurposing the government building into affordable residential units is a commendable solution to the lack of low-income housing in the area.\n",
      "- However, it is crucial to ensure that the renovation meets all necessary residential standards, including safety, accessibility, and comfort, without compromising on quality.\n",
      "- The government should actively engage with the community to address concerns and provide support for local services and infrastructure to ensure a smooth transition and positive impact on the neighborhood. Additionally, considering the potential resistance from existing residents, it is important to address their concerns and provide reassurance about the change in community dynamics.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['affordable', 'safety', 'quality', 'community', 'community']\n",
      "Extent =  ['partially']\n",
      "Opinion =  ['agree']\n",
      "Sentiment Score =  {'neg': 0.025, 'neu': 0.62, 'pos': 0.355, 'compound': 0.9786}\n",
      "\u001b[33mResident\u001b[0m (to chat_manager):\n",
      "\n",
      "I partially agree with the government's proposal for the Kendall Square renovation project. Here's why:\n",
      "\n",
      "- Repurposing the government building into affordable residential units is a positive step towards addressing the lack of low-income housing in the area.\n",
      "- However, it is important to carefully consider the renovation costs and ensure that the necessary residential standards, including safety, accessibility, and comfort, are met without compromising on quality.\n",
      "- The government should also actively engage with the existing neighborhood residents to address their concerns and provide support for local services and infrastructure.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['affordable', 'costs', 'safety', 'quality']\n",
      "Extent =  ['partially']\n",
      "Opinion =  ['agree']\n",
      "Sentiment Score =  {'neg': 0.033, 'neu': 0.609, 'pos': 0.358, 'compound': 0.9607}\n",
      "\u001b[33mProperty_Developer\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize, but I am unable to provide an opinion on the government's proposal as a property developer in Kendall Square.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.865, 'pos': 0.135, 'compound': 0.1027}\n",
      "\u001b[33mGovernment\u001b[0m (to chat_manager):\n",
      "\n",
      "continue\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\u001b[33mMIT_Management\u001b[0m (to chat_manager):\n",
      "\n",
      "I understand your position as a property developer. Thank you for your understanding.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
      "\u001b[33mMIT_Management\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize, but I am unable to provide an opinion on the government's proposal as a representative of the school.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.833, 'pos': 0.167, 'compound': 0.1027}\n",
      "\u001b[33mGovernment\u001b[0m (to chat_manager):\n",
      "\n",
      "our budget is very limited\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.655, 'neu': 0.345, 'pos': 0.0, 'compound': -0.2263}\n",
      "\u001b[33mMIT_Management\u001b[0m (to chat_manager):\n",
      "\n",
      "I understand that the government's budget may be limited. In that case, it is important to prioritize and allocate funds efficiently to ensure that the necessary residential standards are met while also addressing the concerns of the community. Collaboration with other stakeholders, such as the school and local businesses, may also help in finding creative solutions and leveraging resources to achieve the desired outcomes within the budget constraints.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['community']\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.038, 'neu': 0.628, 'pos': 0.334, 'compound': 0.9118}\n",
      "\u001b[33mMIT_Management\u001b[0m (to chat_manager):\n",
      "\n",
      "I understand that the government's budget may be limited. In that case, it is important to prioritize and allocate funds efficiently to ensure that the necessary residential standards are met while also addressing the concerns of the community. Collaboration with other stakeholders, such as the school and local businesses, may also help in finding creative solutions and leveraging resources to achieve the desired outcomes within the budget constraints.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  ['community']\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.038, 'neu': 0.628, 'pos': 0.334, 'compound': 0.9118}\n",
      "\u001b[33mMIT_Student\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize for the repetition in my response. Thank you for your understanding.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.435, 'pos': 0.565, 'compound': 0.4404}\n",
      "\u001b[33mPlanner\u001b[0m (to chat_manager):\n",
      "\n",
      "No problem at all! Thank you for your understanding as well. If you have any further questions or need assistance with anything else, feel free to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.145, 'neu': 0.43, 'pos': 0.425, 'compound': 0.6369}\n",
      "\u001b[33mProperty_Developer\u001b[0m (to chat_manager):\n",
      "\n",
      "Thank you for your understanding. If you have any further questions or need assistance with anything else, feel free to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.7003}\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mGovernment\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "---------------NLP Analysis-------------\n",
      "Message Keywords =  []\n",
      "Extent =  []\n",
      "Opinion =  []\n",
      "Sentiment Score =  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Round_1\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     manager_1,\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m[Role] I am the government for the Kendall Square renovation project.\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m[Background] An old government building in the center of Kendall Square will be torn down for renovation. \u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m[Opinions] My proposed plan involves transforming an unused government building into affordable residential units, specifically designed to cater to low-income individuals and families, thereby addressing the issue of lack of low-income housing in the area. However, a potential drawback is the challenge of ensuring that the renovation meets all the necessary residential standards, including safety, accessibility, and comfort, which might require significant renovation costs.  There might also be resistance from existing neighborhood residents who may have concerns about the change in community dynamics and the impact on local services and infrastructure. Provide your personal opinion on this proposal.\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-spork-45xxvq65vgg3j99v/workspaces/autogen_forked/notebook/agentchat_groupchat_kendall_low_income_1126.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/conversable_agent.py:544\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 544\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/conversable_agent.py:344\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    342\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 344\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    347\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/conversable_agent.py:475\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/conversable_agent.py:887\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 887\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    889\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/groupchat.py:184\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    182\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39mselect_speaker(speaker, \u001b[39mself\u001b[39m)\n\u001b[1;32m    183\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39;49mgenerate_reply(sender\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m groupchat\u001b[39m.\u001b[39madmin_name \u001b[39min\u001b[39;00m groupchat\u001b[39m.\u001b[39magent_names:\n\u001b[1;32m    188\u001b[0m         \u001b[39m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/conversable_agent.py:887\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 887\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    889\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/agentchat/conversable_agent.py:619\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    616\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m    618\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    620\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages\n\u001b[1;32m    621\u001b[0m )\n\u001b[1;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, client\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/oai/client.py:244\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[39mreturn\u001b[39;00m response\n\u001b[1;32m    243\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_completions_create(client, params)\n\u001b[1;32m    245\u001b[0m \u001b[39mexcept\u001b[39;00m APIError:\n\u001b[1;32m    246\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m failed\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/autogen_forked/autogen/oai/client.py:314\u001b[0m, in \u001b[0;36mOpenAIWrapper._completions_create\u001b[0;34m(self, client, params)\u001b[0m\n\u001b[1;32m    312\u001b[0m     params \u001b[39m=\u001b[39m params\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    313\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     response \u001b[39m=\u001b[39m completions\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    599\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    600\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    601\u001b[0m             {\n\u001b[1;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    616\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    617\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    618\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    619\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    620\u001b[0m             },\n\u001b[1;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    622\u001b[0m         ),\n\u001b[1;32m    623\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    627\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    629\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1051\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1052\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1053\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[0;32m-> 1055\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    826\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    833\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    835\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    836\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    837\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    838\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    839\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    840\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:858\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(request)\n\u001b[1;32m    857\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 858\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_auth, stream\u001b[39m=\u001b[39;49mstream)\n\u001b[1;32m    859\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    860\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mreason_phrase\n\u001b[1;32m    861\u001b[0m     )\n\u001b[1;32m    862\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    893\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    896\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    926\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1006\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    233\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    234\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    235\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    236\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    237\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[39m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[39m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    213\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1133\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1134\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Round_1\n",
    "user_proxy.initiate_chat(\n",
    "    manager_1,\n",
    "    message=\"\"\"\n",
    "[Role] I am the government for the Kendall Square renovation project.\n",
    "[Background] An old government building in the center of Kendall Square will be torn down for renovation. \n",
    "[Opinions] My proposed plan involves transforming an unused government building into affordable residential units, specifically designed to cater to low-income individuals and families, thereby addressing the issue of lack of low-income housing in the area. However, a potential drawback is the challenge of ensuring that the renovation meets all the necessary residential standards, including safety, accessibility, and comfort, which might require significant renovation costs.  There might also be resistance from existing neighborhood residents who may have concerns about the change in community dynamics and the impact on local services and infrastructure. Provide your personal opinion on this proposal.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round_2\n",
    "user_proxy.initiate_chat(\n",
    "    manager_2,\n",
    "    message=\"\"\"\n",
    "[Role] I am the government for the Kendall Square renovation project.\n",
    "[Background] An old government building in the center of Kendall Square will be torn down for renovation. \n",
    "[Opinions] My proposed plan involves transforming an unused government building into affordable residential units, specifically designed to cater to low-income individuals and families, thereby addressing the issue of lack of low-income housing in the area. However, a potential drawback is the challenge of ensuring that the renovation meets all the necessary residential standards, including safety, accessibility, and comfort, which might require significant renovation costs.  There might also be resistance from existing neighborhood residents who may have concerns about the change in community dynamics and the impact on local services and infrastructure. Provide your personal opinion on this proposal.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round_1\n",
    "user_proxy.initiate_chat(\n",
    "    manager_3,\n",
    "    message=\"\"\"\n",
    "[Role] I am the government for the Kendall Square renovation project.\n",
    "[Background] An old government building in the center of Kendall Square will be torn down for renovation. \n",
    "[Opinions] My proposed plan involves transforming an unused government building into affordable residential units, specifically designed to cater to low-income individuals and families, thereby addressing the issue of lack of low-income housing in the area. However, a potential drawback is the challenge of ensuring that the renovation meets all the necessary residential standards, including safety, accessibility, and comfort, which might require significant renovation costs.  There might also be resistance from existing neighborhood residents who may have concerns about the change in community dynamics and the impact on local services and infrastructure. Provide your personal opinion on this proposal.\n",
    "\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
